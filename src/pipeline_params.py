import json
import os
from typing import Dict, List, Tuple, Optional
import logging
from dataclasses import dataclass, field


def generate_s3_path(
    config: AppConfig,
    pipeline_id: str,
    job_id: str = None,
    filename: str = None,
    is_input: bool = False,
    catchment_id: str = None,
) -> str:
    """
    Generates a structured S3 path for pipeline artifacts (outputs or generated inputs)
    within the configured bucket.
    """
    parts = [
        f"s3://{config.s3.bucket}",
        config.s3.base_prefix,
        f"pipeline_{pipeline_id}",
    ]
    if catchment_id:
        # Group intermediate files by catchment under the pipeline
        parts.append(f"catchment_{catchment_id}")
    elif (
        job_id
    ):  # Note: Changed order, catchment is more specific than job for grouping I/O
        job_suffix = job_id.split("/")[-1] if "/" in job_id else job_id
        parts.append(f"job_{job_suffix}")

    # Distinguish inputs generated *by* the pipeline from job outputs
    if is_input:
        parts.append(
            "inputs"
        )  # e.g., the catchment_data.json generated by the pipeline
    else:
        parts.append("outputs")  # e.g., the inundation .tif file produced by the job

    if filename:
        parts.append(filename)
    return "/".join(parts)


def _stringify_meta(meta: Dict) -> Dict:
    """Ensures all values in the metadata dictionary are strings."""
    return {k: str(v) if v is not None else "" for k, v in meta.items()}


def prepare_inundator_dispatch_info(
    config: AppConfig,
    pipeline_id: str,
    catchment_id: str,
) -> Dict:  # Returns only the dispatch metadata dictionary
    """
    Prepares metadata for dispatching a hand_inundator job. Determines the S3 paths
    for the input JSON (which the pipeline is responsible for writing) and the
    output TIF (where the job will write).

    Args:
        config: Application configuration.
        pipeline_id: ID of the current pipeline run.
        catchment_id: ID of the specific catchment.

    Returns:
        dispatch_meta: Stringified metadata dictionary for the Nomad job dispatch.

    Raises:
        # Potential errors could arise from config access if not properly loaded
    """
    logging.debug(
        f"Preparing inundator dispatch metadata for pipeline={pipeline_id}, catchment={catchment_id}"
    )

    # --- 1. Determine S3 Path for the Input JSON (pipeline writes here) ---
    # This path MUST match the path calculated and used by the pipeline's write step.
    input_json_s3_path = generate_s3_path(
        config,
        pipeline_id,
        catchment_id=catchment_id,
        filename="catchment_data.json",  # Standardized name job expects
        is_input=True,
    )

    # --- 2. Determine Job Output Path (job writes here) ---
    output_fim_s3_path = generate_s3_path(
        config,
        pipeline_id,
        catchment_id=catchment_id,
        filename="inundation_output.tif",  # Standardized name for the job's output
        is_input=False,
    )

    # --- 3. Assemble Dispatch Metadata ---
    # This metadata tells the job where to find its input JSON and where to write its output
    dispatch_meta = {
        "pipeline_id": pipeline_id,
        "catchment_data_path": input_json_s3_path,  # Path to the JSON the pipeline writes
        "forecast_path": f"s3://{config.s3.bucket}/{config.forecast_csv}",  # Path to the forecast CSV on S3
        "output_path": output_fim_s3_path,
        "fim_type": config.defaults.fim_type,
        "geo_mem_cache": config.defaults.geo_mem_cache_inundator,
    }

    # Return only the stringified metadata
    return _stringify_meta(dispatch_meta)


def prepare_mosaicker_dispatch_meta(
    config: AppConfig,
    pipeline_id: str,
    completed_inundator_outputs: List[str],
) -> Dict:
    """
    Prepares metadata for the fim_mosaicker job dispatch. Assumes inundator outputs
    are full S3 paths.
    """
    logging.debug(f"Preparing mosaicker params for pipeline={pipeline_id}")

    final_output_s3_path = generate_s3_path(
        config,
        pipeline_id,
        # TODO: add job_id and catchment_id here
        filename=f"{pipeline_id}_mosaic.tif",
        is_input=False,
    )

    # --- 2. Assemble Dispatch Metadata ---
    dispatch_meta = {
        "pipeline_id": pipeline_id,
        "raster_paths": json.dumps(completed_inundator_outputs),
        "output_path": final_output_s3_path,
        "fim_type": config.defaults.fim_type,
        "geo_mem_cache": config.defaults.geo_mem_cache_mosaicker,
    }

    return _stringify_meta(dispatch_meta)
